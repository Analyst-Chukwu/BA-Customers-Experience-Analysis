{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ff49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEB SCRAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa6d756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "027a38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 400\n",
    "\n",
    "reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8df891d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "56fef1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "80d8c0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fb02c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ---> 309 total reviews\n"
     ]
    }
   ],
   "source": [
    "content = response.content\n",
    "parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "    reviews.append(para.get_text())\n",
    "    \n",
    "print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "07385483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hannover - LHR. What a miserable experience th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCL-LHR-LAX / LAS-LHR-NCL. NCL-LHR A320. Comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flew from LGW to PFO and back recently. Plane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LHR-JNB (South Africa). Booking done from site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flew earlier this month LHR to IST in Club Eur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Hannover - LHR. What a miserable experience th...\n",
       "1  NCL-LHR-LAX / LAS-LHR-NCL. NCL-LHR A320. Comfo...\n",
       "2  Flew from LGW to PFO and back recently. Plane ...\n",
       "3  LHR-JNB (South Africa). Booking done from site...\n",
       "4  Flew earlier this month LHR to IST in Club Eur..."
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2dcaf57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r\"C:\\Users\\user\\Desktop\\For Github\\Airline_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2320c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2b2e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customers_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hannover - LHR. What a miserable experience th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NCL-LHR-LAX / LAS-LHR-NCL. NCL-LHR A320. Comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Flew from LGW to PFO and back recently. Plane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LHR-JNB (South Africa). Booking done from site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Flew earlier this month LHR to IST in Club Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>Flew LHR - VIE return operated by bmi but BA a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>LHR to HAM. Purser addresses all club passenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>My son who had worked for British Airways urge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>London City-New York JFK via Shannon on A318 b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>SIN-LHR BA12 B747-436 First Class. Old aircraf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                  customers_reviews\n",
       "0             0  Hannover - LHR. What a miserable experience th...\n",
       "1             1  NCL-LHR-LAX / LAS-LHR-NCL. NCL-LHR A320. Comfo...\n",
       "2             2  Flew from LGW to PFO and back recently. Plane ...\n",
       "3             3  LHR-JNB (South Africa). Booking done from site...\n",
       "4             4  Flew earlier this month LHR to IST in Club Eur...\n",
       "..          ...                                                ...\n",
       "304         304  Flew LHR - VIE return operated by bmi but BA a...\n",
       "305         305  LHR to HAM. Purser addresses all club passenge...\n",
       "306         306  My son who had worked for British Airways urge...\n",
       "307         307  London City-New York JFK via Shannon on A318 b...\n",
       "308         308  SIN-LHR BA12 B747-436 First Class. Old aircraf...\n",
       "\n",
       "[309 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the data\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\user\\Desktop\\For Github\\Airline_final.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "db3cd372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customers_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hannover - LHR. What a miserable experience th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NCL-LHR-LAX / LAS-LHR-NCL. NCL-LHR A320. Comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Flew from LGW to PFO and back recently. Plane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LHR-JNB (South Africa). Booking done from site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Flew earlier this month LHR to IST in Club Eur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  customers_reviews\n",
       "0           0  Hannover - LHR. What a miserable experience th...\n",
       "1           1  NCL-LHR-LAX / LAS-LHR-NCL. NCL-LHR A320. Comfo...\n",
       "2           2  Flew from LGW to PFO and back recently. Plane ...\n",
       "3           3  LHR-JNB (South Africa). Booking done from site...\n",
       "4           4  Flew earlier this month LHR to IST in Club Eur..."
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed4e933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hannover - LHR. What a miserable experience this was. This return ticket was £950 for a total of about 140 mins flying time. I checked in online and there was considerable delays on this as there was following a phone call back to the UK an equipment change from an A319 to an A320. Anyway I checked in online eventually and made my way through security. I asked an information post - as to where the Club / Business class lounge was and I was told it was land side and between \"this terminal and the next terminal\". I could not believe it. Surely a simple prompt online when checking in - could have told me this. Flight left on time a reasonable light lunch and three Gin and Tonics later we got stacked over the East End for 25 minutes but landed \"ahead of schedule\". A miserable experience from the so called \"world\\'s favorite airline\".'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['customers_reviews'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e23c8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7b3b184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flew Heathrow to Lyon return. Late flight on the way out but made up all but 10 mins of the time. Catering hardly worth the effort as comprised unappetising looking sandwich and one drink (not even tea or coffee on the outbound). Crew good and check in very good especially at Heathrow.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = df['customers_reviews'][50]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0321e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0153c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c3c8342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flew',\n",
       " 'Heathrow',\n",
       " 'to',\n",
       " 'Lyon',\n",
       " 'return',\n",
       " '.',\n",
       " 'Late',\n",
       " 'flight',\n",
       " 'on',\n",
       " 'the']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nltk.word_tokenize(example)\n",
    "token[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9b9c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6311f923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.836, 'pos': 0.164, 'compound': 0.8628}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d66d80de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ba1388f00c4ad2857e74e76dfef7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/309 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run the polarity score on the entire dataset\n",
    "\n",
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['customers_reviews']\n",
    "    myid = row['Unnamed: 0']\n",
    "    res[myid] = sia.polarity_scores(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87843041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'neg': 0.054, 'neu': 0.905, 'pos': 0.041, 'compound': -0.2517},\n",
       " 1: {'neg': 0.068, 'neu': 0.742, 'pos': 0.19, 'compound': 0.9952},\n",
       " 2: {'neg': 0.1, 'neu': 0.751, 'pos': 0.149, 'compound': 0.9081},\n",
       " 3: {'neg': 0.0, 'neu': 0.845, 'pos': 0.155, 'compound': 0.9637},\n",
       " 4: {'neg': 0.037, 'neu': 0.83, 'pos': 0.133, 'compound': 0.7574},\n",
       " 5: {'neg': 0.088, 'neu': 0.891, 'pos': 0.021, 'compound': -0.8436},\n",
       " 6: {'neg': 0.144, 'neu': 0.707, 'pos': 0.149, 'compound': 0.5494},\n",
       " 7: {'neg': 0.117, 'neu': 0.827, 'pos': 0.055, 'compound': -0.8342},\n",
       " 8: {'neg': 0.076, 'neu': 0.799, 'pos': 0.125, 'compound': 0.6151},\n",
       " 9: {'neg': 0.0, 'neu': 0.743, 'pos': 0.257, 'compound': 0.9826},\n",
       " 10: {'neg': 0.0, 'neu': 0.812, 'pos': 0.188, 'compound': 0.9885},\n",
       " 11: {'neg': 0.118, 'neu': 0.708, 'pos': 0.174, 'compound': 0.5263},\n",
       " 12: {'neg': 0.059, 'neu': 0.841, 'pos': 0.1, 'compound': 0.5566},\n",
       " 13: {'neg': 0.054, 'neu': 0.809, 'pos': 0.137, 'compound': 0.9798},\n",
       " 14: {'neg': 0.061, 'neu': 0.782, 'pos': 0.157, 'compound': 0.992},\n",
       " 15: {'neg': 0.139, 'neu': 0.73, 'pos': 0.131, 'compound': 0.4582},\n",
       " 16: {'neg': 0.0, 'neu': 0.764, 'pos': 0.236, 'compound': 0.9725},\n",
       " 17: {'neg': 0.064, 'neu': 0.874, 'pos': 0.062, 'compound': 0.4544},\n",
       " 18: {'neg': 0.081, 'neu': 0.903, 'pos': 0.016, 'compound': -0.9408},\n",
       " 19: {'neg': 0.019, 'neu': 0.853, 'pos': 0.128, 'compound': 0.7688},\n",
       " 20: {'neg': 0.0, 'neu': 0.791, 'pos': 0.209, 'compound': 0.9472},\n",
       " 21: {'neg': 0.0, 'neu': 0.727, 'pos': 0.273, 'compound': 0.9838},\n",
       " 22: {'neg': 0.0, 'neu': 0.693, 'pos': 0.307, 'compound': 0.923},\n",
       " 23: {'neg': 0.137, 'neu': 0.767, 'pos': 0.095, 'compound': -0.7542},\n",
       " 24: {'neg': 0.04, 'neu': 0.615, 'pos': 0.346, 'compound': 0.9715},\n",
       " 25: {'neg': 0.0, 'neu': 0.63, 'pos': 0.37, 'compound': 0.9842},\n",
       " 26: {'neg': 0.018, 'neu': 0.799, 'pos': 0.183, 'compound': 0.9542},\n",
       " 27: {'neg': 0.189, 'neu': 0.726, 'pos': 0.086, 'compound': -0.974},\n",
       " 28: {'neg': 0.126, 'neu': 0.68, 'pos': 0.194, 'compound': 0.9878},\n",
       " 29: {'neg': 0.09, 'neu': 0.745, 'pos': 0.165, 'compound': 0.6378},\n",
       " 30: {'neg': 0.0, 'neu': 0.94, 'pos': 0.06, 'compound': 0.4215},\n",
       " 31: {'neg': 0.0, 'neu': 0.91, 'pos': 0.09, 'compound': 0.7579},\n",
       " 32: {'neg': 0.0, 'neu': 0.824, 'pos': 0.176, 'compound': 0.9749},\n",
       " 33: {'neg': 0.09, 'neu': 0.857, 'pos': 0.053, 'compound': -0.7342},\n",
       " 34: {'neg': 0.075, 'neu': 0.88, 'pos': 0.046, 'compound': -0.8338},\n",
       " 35: {'neg': 0.054, 'neu': 0.823, 'pos': 0.122, 'compound': 0.8231},\n",
       " 36: {'neg': 0.068, 'neu': 0.783, 'pos': 0.148, 'compound': 0.9147},\n",
       " 37: {'neg': 0.08, 'neu': 0.809, 'pos': 0.11, 'compound': 0.7425},\n",
       " 38: {'neg': 0.0, 'neu': 0.684, 'pos': 0.316, 'compound': 0.9705},\n",
       " 39: {'neg': 0.036, 'neu': 0.853, 'pos': 0.11, 'compound': 0.8707},\n",
       " 40: {'neg': 0.059, 'neu': 0.909, 'pos': 0.032, 'compound': -0.6388},\n",
       " 41: {'neg': 0.154, 'neu': 0.777, 'pos': 0.069, 'compound': -0.867},\n",
       " 42: {'neg': 0.141, 'neu': 0.752, 'pos': 0.107, 'compound': -0.4158},\n",
       " 43: {'neg': 0.046, 'neu': 0.817, 'pos': 0.137, 'compound': 0.9371},\n",
       " 44: {'neg': 0.213, 'neu': 0.714, 'pos': 0.073, 'compound': -0.9142},\n",
       " 45: {'neg': 0.04, 'neu': 0.727, 'pos': 0.233, 'compound': 0.984},\n",
       " 46: {'neg': 0.034, 'neu': 0.846, 'pos': 0.12, 'compound': 0.9741},\n",
       " 47: {'neg': 0.028, 'neu': 0.972, 'pos': 0.0, 'compound': -0.2023},\n",
       " 48: {'neg': 0.017, 'neu': 0.81, 'pos': 0.173, 'compound': 0.8858},\n",
       " 49: {'neg': 0.167, 'neu': 0.762, 'pos': 0.071, 'compound': -0.9413},\n",
       " 50: {'neg': 0.0, 'neu': 0.836, 'pos': 0.164, 'compound': 0.8628},\n",
       " 51: {'neg': 0.019, 'neu': 0.836, 'pos': 0.146, 'compound': 0.8734},\n",
       " 52: {'neg': 0.055, 'neu': 0.791, 'pos': 0.155, 'compound': 0.969},\n",
       " 53: {'neg': 0.093, 'neu': 0.853, 'pos': 0.054, 'compound': -0.6167},\n",
       " 54: {'neg': 0.044, 'neu': 0.861, 'pos': 0.095, 'compound': 0.899},\n",
       " 55: {'neg': 0.05, 'neu': 0.8, 'pos': 0.15, 'compound': 0.9739},\n",
       " 56: {'neg': 0.135, 'neu': 0.789, 'pos': 0.076, 'compound': -0.8612},\n",
       " 57: {'neg': 0.145, 'neu': 0.724, 'pos': 0.131, 'compound': -0.5802},\n",
       " 58: {'neg': 0.137, 'neu': 0.711, 'pos': 0.151, 'compound': 0.412},\n",
       " 59: {'neg': 0.044, 'neu': 0.755, 'pos': 0.202, 'compound': 0.9791},\n",
       " 60: {'neg': 0.04, 'neu': 0.766, 'pos': 0.194, 'compound': 0.9672},\n",
       " 61: {'neg': 0.091, 'neu': 0.839, 'pos': 0.07, 'compound': -0.5696},\n",
       " 62: {'neg': 0.0, 'neu': 0.887, 'pos': 0.113, 'compound': 0.8122},\n",
       " 63: {'neg': 0.044, 'neu': 0.877, 'pos': 0.079, 'compound': 0.6439},\n",
       " 64: {'neg': 0.085, 'neu': 0.704, 'pos': 0.211, 'compound': 0.9861},\n",
       " 65: {'neg': 0.052, 'neu': 0.849, 'pos': 0.1, 'compound': 0.9185},\n",
       " 66: {'neg': 0.043, 'neu': 0.899, 'pos': 0.058, 'compound': 0.5648},\n",
       " 67: {'neg': 0.038, 'neu': 0.786, 'pos': 0.177, 'compound': 0.9477},\n",
       " 68: {'neg': 0.105, 'neu': 0.871, 'pos': 0.024, 'compound': -0.8201},\n",
       " 69: {'neg': 0.103, 'neu': 0.837, 'pos': 0.06, 'compound': -0.5305},\n",
       " 70: {'neg': 0.0, 'neu': 0.836, 'pos': 0.164, 'compound': 0.9562},\n",
       " 71: {'neg': 0.075, 'neu': 0.863, 'pos': 0.062, 'compound': -0.4408},\n",
       " 72: {'neg': 0.069, 'neu': 0.692, 'pos': 0.239, 'compound': 0.984},\n",
       " 73: {'neg': 0.094, 'neu': 0.846, 'pos': 0.06, 'compound': -0.6999},\n",
       " 74: {'neg': 0.017, 'neu': 0.917, 'pos': 0.066, 'compound': 0.8186},\n",
       " 75: {'neg': 0.0, 'neu': 0.753, 'pos': 0.247, 'compound': 0.9468},\n",
       " 76: {'neg': 0.028, 'neu': 0.741, 'pos': 0.231, 'compound': 0.9884},\n",
       " 77: {'neg': 0.102, 'neu': 0.777, 'pos': 0.121, 'compound': 0.688},\n",
       " 78: {'neg': 0.014, 'neu': 0.821, 'pos': 0.165, 'compound': 0.9753},\n",
       " 79: {'neg': 0.107, 'neu': 0.849, 'pos': 0.045, 'compound': -0.8528},\n",
       " 80: {'neg': 0.103, 'neu': 0.822, 'pos': 0.074, 'compound': -0.6655},\n",
       " 81: {'neg': 0.08, 'neu': 0.796, 'pos': 0.124, 'compound': 0.8778},\n",
       " 82: {'neg': 0.033, 'neu': 0.809, 'pos': 0.158, 'compound': 0.8867},\n",
       " 83: {'neg': 0.0, 'neu': 0.739, 'pos': 0.261, 'compound': 0.908},\n",
       " 84: {'neg': 0.015, 'neu': 0.704, 'pos': 0.282, 'compound': 0.9867},\n",
       " 85: {'neg': 0.051, 'neu': 0.847, 'pos': 0.102, 'compound': 0.8966},\n",
       " 86: {'neg': 0.119, 'neu': 0.77, 'pos': 0.111, 'compound': -0.2252},\n",
       " 87: {'neg': 0.026, 'neu': 0.771, 'pos': 0.203, 'compound': 0.9862},\n",
       " 88: {'neg': 0.053, 'neu': 0.799, 'pos': 0.148, 'compound': 0.8244},\n",
       " 89: {'neg': 0.061, 'neu': 0.849, 'pos': 0.091, 'compound': 0.8316},\n",
       " 90: {'neg': 0.038, 'neu': 0.732, 'pos': 0.231, 'compound': 0.9817},\n",
       " 91: {'neg': 0.103, 'neu': 0.868, 'pos': 0.029, 'compound': -0.6249},\n",
       " 92: {'neg': 0.053, 'neu': 0.841, 'pos': 0.106, 'compound': 0.9369},\n",
       " 93: {'neg': 0.025, 'neu': 0.854, 'pos': 0.121, 'compound': 0.9759},\n",
       " 94: {'neg': 0.093, 'neu': 0.729, 'pos': 0.178, 'compound': 0.8963},\n",
       " 95: {'neg': 0.03, 'neu': 0.97, 'pos': 0.0, 'compound': -0.5267},\n",
       " 96: {'neg': 0.026, 'neu': 0.826, 'pos': 0.148, 'compound': 0.918},\n",
       " 97: {'neg': 0.119, 'neu': 0.816, 'pos': 0.064, 'compound': -0.6249},\n",
       " 98: {'neg': 0.0, 'neu': 0.823, 'pos': 0.177, 'compound': 0.8777},\n",
       " 99: {'neg': 0.055, 'neu': 0.87, 'pos': 0.074, 'compound': 0.6467},\n",
       " 100: {'neg': 0.059, 'neu': 0.792, 'pos': 0.149, 'compound': 0.972},\n",
       " 101: {'neg': 0.0, 'neu': 0.707, 'pos': 0.293, 'compound': 0.9631},\n",
       " 102: {'neg': 0.046, 'neu': 0.756, 'pos': 0.199, 'compound': 0.9911},\n",
       " 103: {'neg': 0.077, 'neu': 0.787, 'pos': 0.136, 'compound': 0.8775},\n",
       " 104: {'neg': 0.0, 'neu': 0.601, 'pos': 0.399, 'compound': 0.9273},\n",
       " 105: {'neg': 0.109, 'neu': 0.82, 'pos': 0.071, 'compound': -0.928},\n",
       " 106: {'neg': 0.022, 'neu': 0.816, 'pos': 0.161, 'compound': 0.9735},\n",
       " 107: {'neg': 0.049, 'neu': 0.787, 'pos': 0.164, 'compound': 0.9567},\n",
       " 108: {'neg': 0.085, 'neu': 0.85, 'pos': 0.065, 'compound': 0.0},\n",
       " 109: {'neg': 0.148, 'neu': 0.676, 'pos': 0.176, 'compound': 0.6986},\n",
       " 110: {'neg': 0.022, 'neu': 0.853, 'pos': 0.124, 'compound': 0.8382},\n",
       " 111: {'neg': 0.181, 'neu': 0.748, 'pos': 0.071, 'compound': -0.9438},\n",
       " 112: {'neg': 0.0, 'neu': 0.833, 'pos': 0.167, 'compound': 0.7184},\n",
       " 113: {'neg': 0.0, 'neu': 0.741, 'pos': 0.259, 'compound': 0.8271},\n",
       " 114: {'neg': 0.082, 'neu': 0.79, 'pos': 0.128, 'compound': 0.6908},\n",
       " 115: {'neg': 0.03, 'neu': 0.836, 'pos': 0.134, 'compound': 0.7717},\n",
       " 116: {'neg': 0.038, 'neu': 0.787, 'pos': 0.176, 'compound': 0.9921},\n",
       " 117: {'neg': 0.095, 'neu': 0.813, 'pos': 0.092, 'compound': -0.1027},\n",
       " 118: {'neg': 0.013, 'neu': 0.824, 'pos': 0.163, 'compound': 0.9494},\n",
       " 119: {'neg': 0.046, 'neu': 0.833, 'pos': 0.121, 'compound': 0.9654},\n",
       " 120: {'neg': 0.022, 'neu': 0.724, 'pos': 0.254, 'compound': 0.9721},\n",
       " 121: {'neg': 0.02, 'neu': 0.805, 'pos': 0.175, 'compound': 0.9755},\n",
       " 122: {'neg': 0.017, 'neu': 0.887, 'pos': 0.096, 'compound': 0.8805},\n",
       " 123: {'neg': 0.062, 'neu': 0.938, 'pos': 0.0, 'compound': -0.4404},\n",
       " 124: {'neg': 0.061, 'neu': 0.859, 'pos': 0.08, 'compound': 0.6757},\n",
       " 125: {'neg': 0.0, 'neu': 0.872, 'pos': 0.128, 'compound': 0.5719},\n",
       " 126: {'neg': 0.0, 'neu': 0.854, 'pos': 0.146, 'compound': 0.9265},\n",
       " 127: {'neg': 0.061, 'neu': 0.873, 'pos': 0.067, 'compound': 0.7633},\n",
       " 128: {'neg': 0.044, 'neu': 0.884, 'pos': 0.072, 'compound': 0.4491},\n",
       " 129: {'neg': 0.086, 'neu': 0.897, 'pos': 0.017, 'compound': -0.8537},\n",
       " 130: {'neg': 0.0, 'neu': 0.917, 'pos': 0.083, 'compound': 0.7003},\n",
       " 131: {'neg': 0.093, 'neu': 0.872, 'pos': 0.035, 'compound': -0.8707},\n",
       " 132: {'neg': 0.0, 'neu': 0.736, 'pos': 0.264, 'compound': 0.9577},\n",
       " 133: {'neg': 0.054, 'neu': 0.793, 'pos': 0.153, 'compound': 0.831},\n",
       " 134: {'neg': 0.074, 'neu': 0.834, 'pos': 0.092, 'compound': 0.5177},\n",
       " 135: {'neg': 0.038, 'neu': 0.694, 'pos': 0.268, 'compound': 0.9815},\n",
       " 136: {'neg': 0.027, 'neu': 0.86, 'pos': 0.112, 'compound': 0.9767},\n",
       " 137: {'neg': 0.228, 'neu': 0.603, 'pos': 0.169, 'compound': -0.3246},\n",
       " 138: {'neg': 0.319, 'neu': 0.555, 'pos': 0.126, 'compound': -0.902},\n",
       " 139: {'neg': 0.153, 'neu': 0.63, 'pos': 0.217, 'compound': 0.9692},\n",
       " 140: {'neg': 0.077, 'neu': 0.625, 'pos': 0.298, 'compound': 0.9715},\n",
       " 141: {'neg': 0.128, 'neu': 0.765, 'pos': 0.108, 'compound': -0.7285},\n",
       " 142: {'neg': 0.023, 'neu': 0.678, 'pos': 0.298, 'compound': 0.994},\n",
       " 143: {'neg': 0.0, 'neu': 0.761, 'pos': 0.239, 'compound': 0.9895},\n",
       " 144: {'neg': 0.17, 'neu': 0.756, 'pos': 0.074, 'compound': -0.9215},\n",
       " 145: {'neg': 0.03, 'neu': 0.783, 'pos': 0.187, 'compound': 0.765},\n",
       " 146: {'neg': 0.026, 'neu': 0.833, 'pos': 0.141, 'compound': 0.9366},\n",
       " 147: {'neg': 0.038, 'neu': 0.943, 'pos': 0.019, 'compound': -0.2598},\n",
       " 148: {'neg': 0.122, 'neu': 0.856, 'pos': 0.022, 'compound': -0.8847},\n",
       " 149: {'neg': 0.123, 'neu': 0.827, 'pos': 0.049, 'compound': -0.9586},\n",
       " 150: {'neg': 0.087, 'neu': 0.844, 'pos': 0.07, 'compound': -0.296},\n",
       " 151: {'neg': 0.0, 'neu': 0.726, 'pos': 0.274, 'compound': 0.9777},\n",
       " 152: {'neg': 0.063, 'neu': 0.839, 'pos': 0.098, 'compound': 0.5022},\n",
       " 153: {'neg': 0.051, 'neu': 0.679, 'pos': 0.27, 'compound': 0.9694},\n",
       " 154: {'neg': 0.047, 'neu': 0.906, 'pos': 0.047, 'compound': 0.296},\n",
       " 155: {'neg': 0.0, 'neu': 0.699, 'pos': 0.301, 'compound': 0.9414},\n",
       " 156: {'neg': 0.082, 'neu': 0.822, 'pos': 0.096, 'compound': 0.7709},\n",
       " 157: {'neg': 0.018, 'neu': 0.899, 'pos': 0.083, 'compound': 0.728},\n",
       " 158: {'neg': 0.049, 'neu': 0.723, 'pos': 0.228, 'compound': 0.9852},\n",
       " 159: {'neg': 0.022, 'neu': 0.819, 'pos': 0.158, 'compound': 0.9793},\n",
       " 160: {'neg': 0.12, 'neu': 0.682, 'pos': 0.198, 'compound': 0.8462},\n",
       " 161: {'neg': 0.052, 'neu': 0.829, 'pos': 0.119, 'compound': 0.8788},\n",
       " 162: {'neg': 0.011, 'neu': 0.783, 'pos': 0.206, 'compound': 0.9738},\n",
       " 163: {'neg': 0.112, 'neu': 0.745, 'pos': 0.143, 'compound': 0.6409},\n",
       " 164: {'neg': 0.097, 'neu': 0.732, 'pos': 0.171, 'compound': 0.9333},\n",
       " 165: {'neg': 0.042, 'neu': 0.809, 'pos': 0.149, 'compound': 0.9485},\n",
       " 166: {'neg': 0.136, 'neu': 0.797, 'pos': 0.067, 'compound': -0.8165},\n",
       " 167: {'neg': 0.0, 'neu': 0.708, 'pos': 0.292, 'compound': 0.9524},\n",
       " 168: {'neg': 0.145, 'neu': 0.779, 'pos': 0.076, 'compound': -0.8576},\n",
       " 169: {'neg': 0.09, 'neu': 0.771, 'pos': 0.138, 'compound': 0.204},\n",
       " 170: {'neg': 0.06, 'neu': 0.871, 'pos': 0.068, 'compound': 0.4692},\n",
       " 171: {'neg': 0.098, 'neu': 0.832, 'pos': 0.07, 'compound': -0.4405},\n",
       " 172: {'neg': 0.089, 'neu': 0.701, 'pos': 0.21, 'compound': 0.7501},\n",
       " 173: {'neg': 0.012, 'neu': 0.856, 'pos': 0.132, 'compound': 0.91},\n",
       " 174: {'neg': 0.138, 'neu': 0.841, 'pos': 0.021, 'compound': -0.9324},\n",
       " 175: {'neg': 0.087, 'neu': 0.858, 'pos': 0.055, 'compound': -0.3197},\n",
       " 176: {'neg': 0.102, 'neu': 0.829, 'pos': 0.07, 'compound': -0.7572},\n",
       " 177: {'neg': 0.088, 'neu': 0.756, 'pos': 0.156, 'compound': 0.8437},\n",
       " 178: {'neg': 0.071, 'neu': 0.82, 'pos': 0.109, 'compound': 0.9152},\n",
       " 179: {'neg': 0.047, 'neu': 0.875, 'pos': 0.078, 'compound': 0.2444},\n",
       " 180: {'neg': 0.106, 'neu': 0.84, 'pos': 0.054, 'compound': -0.8047},\n",
       " 181: {'neg': 0.071, 'neu': 0.891, 'pos': 0.038, 'compound': -0.8485},\n",
       " 182: {'neg': 0.066, 'neu': 0.837, 'pos': 0.098, 'compound': 0.6537},\n",
       " 183: {'neg': 0.168, 'neu': 0.805, 'pos': 0.027, 'compound': -0.8537},\n",
       " 184: {'neg': 0.056, 'neu': 0.849, 'pos': 0.094, 'compound': 0.8242},\n",
       " 185: {'neg': 0.034, 'neu': 0.799, 'pos': 0.167, 'compound': 0.9442},\n",
       " 186: {'neg': 0.073, 'neu': 0.875, 'pos': 0.052, 'compound': -0.3308},\n",
       " 187: {'neg': 0.087, 'neu': 0.785, 'pos': 0.128, 'compound': 0.8614},\n",
       " 188: {'neg': 0.029, 'neu': 0.626, 'pos': 0.346, 'compound': 0.9877},\n",
       " 189: {'neg': 0.123, 'neu': 0.673, 'pos': 0.204, 'compound': 0.3716},\n",
       " 190: {'neg': 0.129, 'neu': 0.821, 'pos': 0.05, 'compound': -0.9432},\n",
       " 191: {'neg': 0.155, 'neu': 0.747, 'pos': 0.098, 'compound': -0.9423},\n",
       " 192: {'neg': 0.212, 'neu': 0.706, 'pos': 0.082, 'compound': -0.9469},\n",
       " 193: {'neg': 0.064, 'neu': 0.872, 'pos': 0.064, 'compound': 0.0044},\n",
       " 194: {'neg': 0.07, 'neu': 0.831, 'pos': 0.099, 'compound': 0.5719},\n",
       " 195: {'neg': 0.053, 'neu': 0.865, 'pos': 0.082, 'compound': 0.7583},\n",
       " 196: {'neg': 0.014, 'neu': 0.696, 'pos': 0.29, 'compound': 0.9825},\n",
       " 197: {'neg': 0.191, 'neu': 0.746, 'pos': 0.063, 'compound': -0.9739},\n",
       " 198: {'neg': 0.047, 'neu': 0.703, 'pos': 0.25, 'compound': 0.9639},\n",
       " 199: {'neg': 0.112, 'neu': 0.838, 'pos': 0.05, 'compound': -0.8312},\n",
       " 200: {'neg': 0.067, 'neu': 0.836, 'pos': 0.097, 'compound': 0.9181},\n",
       " 201: {'neg': 0.0, 'neu': 0.713, 'pos': 0.287, 'compound': 0.9767},\n",
       " 202: {'neg': 0.0, 'neu': 0.695, 'pos': 0.305, 'compound': 0.9816},\n",
       " 203: {'neg': 0.047, 'neu': 0.76, 'pos': 0.193, 'compound': 0.9803},\n",
       " 204: {'neg': 0.128, 'neu': 0.799, 'pos': 0.073, 'compound': -0.5023},\n",
       " 205: {'neg': 0.0, 'neu': 0.897, 'pos': 0.103, 'compound': 0.6696},\n",
       " 206: {'neg': 0.067, 'neu': 0.687, 'pos': 0.246, 'compound': 0.964},\n",
       " 207: {'neg': 0.012, 'neu': 0.863, 'pos': 0.125, 'compound': 0.9269},\n",
       " 208: {'neg': 0.194, 'neu': 0.636, 'pos': 0.17, 'compound': -0.3553},\n",
       " 209: {'neg': 0.053, 'neu': 0.758, 'pos': 0.189, 'compound': 0.9701},\n",
       " 210: {'neg': 0.14, 'neu': 0.528, 'pos': 0.332, 'compound': 0.802},\n",
       " 211: {'neg': 0.016, 'neu': 0.944, 'pos': 0.04, 'compound': 0.2732},\n",
       " 212: {'neg': 0.1, 'neu': 0.837, 'pos': 0.062, 'compound': -0.639},\n",
       " 213: {'neg': 0.034, 'neu': 0.797, 'pos': 0.169, 'compound': 0.8983},\n",
       " 214: {'neg': 0.085, 'neu': 0.834, 'pos': 0.081, 'compound': 0.1188},\n",
       " 215: {'neg': 0.018, 'neu': 0.789, 'pos': 0.193, 'compound': 0.9842},\n",
       " 216: {'neg': 0.14, 'neu': 0.802, 'pos': 0.058, 'compound': -0.7915},\n",
       " 217: {'neg': 0.111, 'neu': 0.81, 'pos': 0.078, 'compound': -0.9357},\n",
       " 218: {'neg': 0.128, 'neu': 0.828, 'pos': 0.044, 'compound': -0.903},\n",
       " 219: {'neg': 0.0, 'neu': 0.721, 'pos': 0.279, 'compound': 0.9419},\n",
       " 220: {'neg': 0.046, 'neu': 0.868, 'pos': 0.086, 'compound': 0.5641},\n",
       " 221: {'neg': 0.09, 'neu': 0.827, 'pos': 0.083, 'compound': -0.5326},\n",
       " 222: {'neg': 0.133, 'neu': 0.789, 'pos': 0.078, 'compound': -0.888},\n",
       " 223: {'neg': 0.101, 'neu': 0.878, 'pos': 0.021, 'compound': -0.9001},\n",
       " 224: {'neg': 0.163, 'neu': 0.732, 'pos': 0.105, 'compound': -0.871},\n",
       " 225: {'neg': 0.033, 'neu': 0.548, 'pos': 0.419, 'compound': 0.9855},\n",
       " 226: {'neg': 0.096, 'neu': 0.774, 'pos': 0.13, 'compound': 0.6318},\n",
       " 227: {'neg': 0.018, 'neu': 0.837, 'pos': 0.146, 'compound': 0.81},\n",
       " 228: {'neg': 0.07, 'neu': 0.892, 'pos': 0.038, 'compound': -0.34},\n",
       " 229: {'neg': 0.022, 'neu': 0.714, 'pos': 0.265, 'compound': 0.9796},\n",
       " 230: {'neg': 0.0, 'neu': 0.639, 'pos': 0.361, 'compound': 0.9412},\n",
       " 231: {'neg': 0.0, 'neu': 0.909, 'pos': 0.091, 'compound': 0.7645},\n",
       " 232: {'neg': 0.105, 'neu': 0.803, 'pos': 0.092, 'compound': -0.2673},\n",
       " 233: {'neg': 0.035, 'neu': 0.829, 'pos': 0.136, 'compound': 0.961},\n",
       " 234: {'neg': 0.02, 'neu': 0.713, 'pos': 0.267, 'compound': 0.9565},\n",
       " 235: {'neg': 0.062, 'neu': 0.823, 'pos': 0.115, 'compound': 0.9156},\n",
       " 236: {'neg': 0.037, 'neu': 0.869, 'pos': 0.094, 'compound': 0.8211},\n",
       " 237: {'neg': 0.067, 'neu': 0.697, 'pos': 0.236, 'compound': 0.9308},\n",
       " 238: {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.9698},\n",
       " 239: {'neg': 0.084, 'neu': 0.82, 'pos': 0.096, 'compound': 0.2006},\n",
       " 240: {'neg': 0.02, 'neu': 0.804, 'pos': 0.177, 'compound': 0.9413},\n",
       " 241: {'neg': 0.081, 'neu': 0.838, 'pos': 0.081, 'compound': 0.5727},\n",
       " 242: {'neg': 0.053, 'neu': 0.83, 'pos': 0.117, 'compound': 0.7855},\n",
       " 243: {'neg': 0.071, 'neu': 0.807, 'pos': 0.122, 'compound': 0.4866},\n",
       " 244: {'neg': 0.076, 'neu': 0.825, 'pos': 0.099, 'compound': 0.321},\n",
       " 245: {'neg': 0.122, 'neu': 0.836, 'pos': 0.042, 'compound': -0.9448},\n",
       " 246: {'neg': 0.023, 'neu': 0.797, 'pos': 0.18, 'compound': 0.9684},\n",
       " 247: {'neg': 0.026, 'neu': 0.847, 'pos': 0.126, 'compound': 0.846},\n",
       " 248: {'neg': 0.122, 'neu': 0.837, 'pos': 0.041, 'compound': -0.7184},\n",
       " 249: {'neg': 0.078, 'neu': 0.866, 'pos': 0.056, 'compound': -0.7096},\n",
       " 250: {'neg': 0.074, 'neu': 0.76, 'pos': 0.166, 'compound': 0.8732},\n",
       " 251: {'neg': 0.138, 'neu': 0.767, 'pos': 0.095, 'compound': -0.445},\n",
       " 252: {'neg': 0.081, 'neu': 0.675, 'pos': 0.243, 'compound': 0.9823},\n",
       " 253: {'neg': 0.053, 'neu': 0.829, 'pos': 0.117, 'compound': 0.5734},\n",
       " 254: {'neg': 0.115, 'neu': 0.727, 'pos': 0.159, 'compound': 0.5416},\n",
       " 255: {'neg': 0.037, 'neu': 0.646, 'pos': 0.317, 'compound': 0.9702},\n",
       " 256: {'neg': 0.117, 'neu': 0.842, 'pos': 0.042, 'compound': -0.9734},\n",
       " 257: {'neg': 0.142, 'neu': 0.669, 'pos': 0.189, 'compound': 0.2892},\n",
       " 258: {'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'compound': 0.9629},\n",
       " 259: {'neg': 0.115, 'neu': 0.73, 'pos': 0.154, 'compound': 0.9794},\n",
       " 260: {'neg': 0.101, 'neu': 0.86, 'pos': 0.039, 'compound': -0.9857},\n",
       " 261: {'neg': 0.113, 'neu': 0.85, 'pos': 0.036, 'compound': -0.7441},\n",
       " 262: {'neg': 0.035, 'neu': 0.802, 'pos': 0.162, 'compound': 0.9745},\n",
       " 263: {'neg': 0.0, 'neu': 0.624, 'pos': 0.376, 'compound': 0.9685},\n",
       " 264: {'neg': 0.087, 'neu': 0.832, 'pos': 0.081, 'compound': -0.4244},\n",
       " 265: {'neg': 0.088, 'neu': 0.831, 'pos': 0.081, 'compound': -0.6295},\n",
       " 266: {'neg': 0.024, 'neu': 0.829, 'pos': 0.147, 'compound': 0.9777},\n",
       " 267: {'neg': 0.021, 'neu': 0.666, 'pos': 0.313, 'compound': 0.9704},\n",
       " 268: {'neg': 0.14, 'neu': 0.839, 'pos': 0.021, 'compound': -0.9062},\n",
       " 269: {'neg': 0.035, 'neu': 0.777, 'pos': 0.188, 'compound': 0.99},\n",
       " 270: {'neg': 0.036, 'neu': 0.913, 'pos': 0.051, 'compound': 0.6035},\n",
       " 271: {'neg': 0.063, 'neu': 0.867, 'pos': 0.07, 'compound': 0.0701},\n",
       " 272: {'neg': 0.026, 'neu': 0.974, 'pos': 0.0, 'compound': -0.2846},\n",
       " 273: {'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'compound': 0.9859},\n",
       " 274: {'neg': 0.0, 'neu': 0.537, 'pos': 0.463, 'compound': 0.8176},\n",
       " 275: {'neg': 0.085, 'neu': 0.72, 'pos': 0.196, 'compound': 0.974},\n",
       " 276: {'neg': 0.097, 'neu': 0.763, 'pos': 0.14, 'compound': 0.7543},\n",
       " 277: {'neg': 0.013, 'neu': 0.804, 'pos': 0.182, 'compound': 0.9255},\n",
       " 278: {'neg': 0.04, 'neu': 0.753, 'pos': 0.207, 'compound': 0.9598},\n",
       " 279: {'neg': 0.0, 'neu': 0.879, 'pos': 0.121, 'compound': 0.8051},\n",
       " 280: {'neg': 0.099, 'neu': 0.859, 'pos': 0.042, 'compound': -0.8523},\n",
       " 281: {'neg': 0.162, 'neu': 0.838, 'pos': 0.0, 'compound': -0.8357},\n",
       " 282: {'neg': 0.147, 'neu': 0.825, 'pos': 0.029, 'compound': -0.9617},\n",
       " 283: {'neg': 0.1, 'neu': 0.8, 'pos': 0.1, 'compound': -0.235},\n",
       " 284: {'neg': 0.022, 'neu': 0.669, 'pos': 0.309, 'compound': 0.9787},\n",
       " 285: {'neg': 0.067, 'neu': 0.901, 'pos': 0.032, 'compound': -0.6823},\n",
       " 286: {'neg': 0.098, 'neu': 0.789, 'pos': 0.113, 'compound': 0.3915},\n",
       " 287: {'neg': 0.113, 'neu': 0.727, 'pos': 0.16, 'compound': 0.7256},\n",
       " 288: {'neg': 0.022, 'neu': 0.812, 'pos': 0.166, 'compound': 0.8807},\n",
       " 289: {'neg': 0.0, 'neu': 0.659, 'pos': 0.341, 'compound': 0.9388},\n",
       " 290: {'neg': 0.022, 'neu': 0.818, 'pos': 0.16, 'compound': 0.9773},\n",
       " 291: {'neg': 0.094, 'neu': 0.853, 'pos': 0.053, 'compound': -0.719},\n",
       " 292: {'neg': 0.095, 'neu': 0.815, 'pos': 0.09, 'compound': 0.0027},\n",
       " 293: {'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'compound': 0.6705},\n",
       " 294: {'neg': 0.025, 'neu': 0.802, 'pos': 0.173, 'compound': 0.875},\n",
       " 295: {'neg': 0.177, 'neu': 0.716, 'pos': 0.107, 'compound': -0.6562},\n",
       " 296: {'neg': 0.123, 'neu': 0.76, 'pos': 0.118, 'compound': -0.2359},\n",
       " 297: {'neg': 0.094, 'neu': 0.848, 'pos': 0.058, 'compound': -0.7254},\n",
       " 298: {'neg': 0.025, 'neu': 0.873, 'pos': 0.102, 'compound': 0.9129},\n",
       " 299: {'neg': 0.067, 'neu': 0.877, 'pos': 0.056, 'compound': -0.2003},\n",
       " 300: {'neg': 0.1, 'neu': 0.879, 'pos': 0.021, 'compound': -0.8763},\n",
       " 301: {'neg': 0.041, 'neu': 0.776, 'pos': 0.182, 'compound': 0.9864},\n",
       " 302: {'neg': 0.057, 'neu': 0.865, 'pos': 0.078, 'compound': 0.3423},\n",
       " 303: {'neg': 0.071, 'neu': 0.834, 'pos': 0.095, 'compound': 0.4417},\n",
       " 304: {'neg': 0.027, 'neu': 0.667, 'pos': 0.306, 'compound': 0.984},\n",
       " 305: {'neg': 0.0, 'neu': 0.712, 'pos': 0.288, 'compound': 0.872},\n",
       " 306: {'neg': 0.056, 'neu': 0.875, 'pos': 0.069, 'compound': 0.4516},\n",
       " 307: {'neg': 0.0, 'neu': 0.711, 'pos': 0.289, 'compound': 0.9148},\n",
       " 308: {'neg': 0.078, 'neu': 0.795, 'pos': 0.126, 'compound': 0.8096}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73a305af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.2517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.9081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.9637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.7574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.9840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.056</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.9148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.078</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.8096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       neg    neu    pos  compound\n",
       "0    0.054  0.905  0.041   -0.2517\n",
       "1    0.068  0.742  0.190    0.9952\n",
       "2    0.100  0.751  0.149    0.9081\n",
       "3    0.000  0.845  0.155    0.9637\n",
       "4    0.037  0.830  0.133    0.7574\n",
       "..     ...    ...    ...       ...\n",
       "304  0.027  0.667  0.306    0.9840\n",
       "305  0.000  0.712  0.288    0.8720\n",
       "306  0.056  0.875  0.069    0.4516\n",
       "307  0.000  0.711  0.289    0.9148\n",
       "308  0.078  0.795  0.126    0.8096\n",
       "\n",
       "[309 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(res).T\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the result into original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aacef28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>customers_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.2517</td>\n",
       "      <td>Hannover - LHR. What a miserable experience th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>NCL-LHR-LAX / LAS-LHR-NCL. NCL-LHR A320. Comfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>Flew from LGW to PFO and back recently. Plane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.9637</td>\n",
       "      <td>LHR-JNB (South Africa). Booking done from site...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.7574</td>\n",
       "      <td>Flew earlier this month LHR to IST in Club Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>Flew LHR - VIE return operated by bmi but BA a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>LHR to HAM. Purser addresses all club passenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>My son who had worked for British Airways urge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>London City-New York JFK via Shannon on A318 b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>SIN-LHR BA12 B747-436 First Class. Old aircraf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    neg    neu    pos  compound  \\\n",
       "0             0  0.054  0.905  0.041   -0.2517   \n",
       "1             1  0.068  0.742  0.190    0.9952   \n",
       "2             2  0.100  0.751  0.149    0.9081   \n",
       "3             3  0.000  0.845  0.155    0.9637   \n",
       "4             4  0.037  0.830  0.133    0.7574   \n",
       "..          ...    ...    ...    ...       ...   \n",
       "304         304  0.027  0.667  0.306    0.9840   \n",
       "305         305  0.000  0.712  0.288    0.8720   \n",
       "306         306  0.056  0.875  0.069    0.4516   \n",
       "307         307  0.000  0.711  0.289    0.9148   \n",
       "308         308  0.078  0.795  0.126    0.8096   \n",
       "\n",
       "                                     customers_reviews  \n",
       "0    Hannover - LHR. What a miserable experience th...  \n",
       "1    NCL-LHR-LAX / LAS-LHR-NCL. NCL-LHR A320. Comfo...  \n",
       "2    Flew from LGW to PFO and back recently. Plane ...  \n",
       "3    LHR-JNB (South Africa). Booking done from site...  \n",
       "4    Flew earlier this month LHR to IST in Club Eur...  \n",
       "..                                                 ...  \n",
       "304  Flew LHR - VIE return operated by bmi but BA a...  \n",
       "305  LHR to HAM. Purser addresses all club passenge...  \n",
       "306  My son who had worked for British Airways urge...  \n",
       "307  London City-New York JFK via Shannon on A318 b...  \n",
       "308  SIN-LHR BA12 B747-436 First Class. Old aircraf...  \n",
       "\n",
       "[309 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reset_index(). rename(columns = {'index': 'Unnamed: 0'}) \n",
    "result= result.merge(df, how = 'left')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the result as excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ad07ad1b-d7f6-4c64-ab8f-7f973ef4b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(r\"C:\\Users\\user\\Desktop\\For Github\\Airline_final_sentiment.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673be29-7bca-4682-8647-4ce8727e3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOPIC MODELLING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c265c6-fdaf-401b-92d9-c729ee9b3f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-hub in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-hub) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-hub) (4.25.3)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install absl-py\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5bffd0f-1897-40eb-96db-ac2c4814b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd646c1f-4305-446b-b8c0-f7511d99328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1d229d-d3f3-4626-be16-99763048fc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e93ab3-7ce1-4702-bba6-18caa1a7d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (4.48.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1909c010-636e-400a-8224-7b87fe52020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Hugging Face\n",
    "from transformers import pipeline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# NLP\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4cda8ed-0684-48df-ac73-6eff11c94559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download some nltk required data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cd353ac-a22b-492d-b976-ff3e6ad97d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal sentence encoder (from Google)\n",
    "USE_encoder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "\n",
    "# Function to use USE encoder\n",
    "def embed(input):\n",
    "    return np.array(USE_encoder(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30672741-2398-45f1-94b5-5a9f3b063b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Get sentiment model from hugging face platform\n",
    "\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dd09aa3-a428-42a1-aefa-50a954a96696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(input):\n",
    "    result = sentiment_model(input[:512])\n",
    "    sign = 1 if(result[0]['label']==\"POSITIVE\") else -1\n",
    "    value = result[0]['score']\n",
    "    return sign*value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8bf41b99-146d-4341-b585-a78425665fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 8)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\user\\Desktop\\For Github\\Airline_final_sentiment.xlsx\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "03e2a910-0435-41ce-8392-a1a7575c2db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>customers_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>LHR-BSL-LHR A319's each way check/bag drop atT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>274</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>Rating : 10/10 Cabin Flown Economy Value for M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.5416</td>\n",
       "      <td>San Diego return business class (the seat was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>I flew from Gatwick to Rome and back on holida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.8734</td>\n",
       "      <td>LHR-MCT-LHR. Excellent outbound flight. Tasty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>London - BKK Premium economy 19/6/14. I always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.9878</td>\n",
       "      <td>Flew LHR-BUD 11 Sep BA866 and return 15 Sep BA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.7342</td>\n",
       "      <td>If there is an alernative I will never fly BA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>DME-LHR July 23 Club World seat 64A. It was qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>LHR-FCO. Flew out Club Europe courtesy of a re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.2  Unnamed: 0  Unnamed: 0.1    neg    neu    pos  compound  \\\n",
       "133           133         133           133  0.054  0.793  0.153    0.8310   \n",
       "274           274         274           274  0.000  0.537  0.463    0.8176   \n",
       "254           254         254           254  0.115  0.727  0.159    0.5416   \n",
       "88             88          88            88  0.053  0.799  0.148    0.8244   \n",
       "51             51          51            51  0.019  0.836  0.146    0.8734   \n",
       "178           178         178           178  0.071  0.820  0.109    0.9152   \n",
       "28             28          28            28  0.126  0.680  0.194    0.9878   \n",
       "33             33          33            33  0.090  0.857  0.053   -0.7342   \n",
       "121           121         121           121  0.020  0.805  0.175    0.9755   \n",
       "9               9           9             9  0.000  0.743  0.257    0.9826   \n",
       "\n",
       "                                     customers_reviews  \n",
       "133  LHR-BSL-LHR A319's each way check/bag drop atT...  \n",
       "274  Rating : 10/10 Cabin Flown Economy Value for M...  \n",
       "254  San Diego return business class (the seat was ...  \n",
       "88   I flew from Gatwick to Rome and back on holida...  \n",
       "51   LHR-MCT-LHR. Excellent outbound flight. Tasty ...  \n",
       "178  London - BKK Premium economy 19/6/14. I always...  \n",
       "28   Flew LHR-BUD 11 Sep BA866 and return 15 Sep BA...  \n",
       "33   If there is an alernative I will never fly BA ...  \n",
       "121  DME-LHR July 23 Club World seat 64A. It was qu...  \n",
       "9    LHR-FCO. Flew out Club Europe courtesy of a re...  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f7d54933-791a-47a3-b171-035b2e516d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# focusing on customers_reviews\n",
    "Air_reviews = df['customers_reviews'].dropna().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "df94e96f-5947-4a09-a15a-aecee7acd512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create topic model\n",
    "\n",
    "class ReviewsTopicModel:\n",
    "\n",
    "    STOPWORDS = stopwords.words('english') # stopwords from ntlk\n",
    "\n",
    "    EMBEDDING_DIM = 512 # USE encoder\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, reviews):\n",
    "        self.X = self.clean(reviews)\n",
    "\n",
    "    # Clean text method\n",
    "    def clean(self, reviews):\n",
    "        # Words to replace\n",
    "        string_map = {'\\r': '', '\\n': '', '/': ' ', \"'\": \"\", '\"': '', 'Trip Verified': '', '|': ''}\n",
    "        reviews_cleaned = reviews[:]\n",
    "        for i in range(len(reviews_cleaned)):\n",
    "            for s in string_map:\n",
    "                reviews_cleaned[i] = reviews_cleaned[i].replace(s, string_map[s]).lower() \n",
    "        # Transform the reviews into embeddings dataframe\n",
    "        X = embed(reviews_cleaned)\n",
    "        X = pd.DataFrame(X)\n",
    "        X.index = reviews_cleaned\n",
    "        return X\n",
    "\n",
    "    # Method to determine number of topics (a.k.a kmeans cluster number)\n",
    "    def elbow_plot(self):\n",
    "        cluster_sizes = list(range(1, 81))\n",
    "        cluster_scores = []\n",
    "        for n in cluster_sizes:\n",
    "            kmeans = KMeans(n_clusters=n)\n",
    "            kmeans.fit(self.X)\n",
    "            cluster_scores.append(kmeans.inertia_)\n",
    "        plt.figure()\n",
    "        plt.plot(cluster_sizes, cluster_scores)\n",
    "        plt.show()\n",
    "\n",
    "    # Method to extract topics from text data\n",
    "    def create_topics(self, num_topics):\n",
    "        # Cluster the reviews\n",
    "        kmeans = KMeans(n_clusters=num_topics)\n",
    "        kmeans.fit(self.X)\n",
    "\n",
    "        # Create the final topics dataframe\n",
    "        topics_df = self.X.copy()\n",
    "        topics_df['topic'] = kmeans.labels_.copy()\n",
    "        topics_df['topic'] = topics_df['topic'].astype(int)\n",
    "\n",
    "        # Create summary keywords per topic\n",
    "        topic_keywords = {}\n",
    "        for topic in topics_df['topic'].unique():\n",
    "            topic_reviews = topics_df.query(\"topic == {}\".format(topic)).index.tolist()\n",
    "            topic_centroid = kmeans.cluster_centers_[topic] # cluster center\n",
    "            topic_keywords[topic] = self.get_closest_words(topic_reviews, topic_centroid)\n",
    "        topics_df['topic_keywords'] = topics_df['topic'].map(topic_keywords)\n",
    "\n",
    "        # Score the sentiment of each review\n",
    "        topics_df['sentiment'] = [sentiment(r) for r in topics_df.index.values.tolist()]\n",
    "\n",
    "        # Final result\n",
    "        self.topics_keywords = topic_keywords\n",
    "        self.topics_df = topics_df.copy()[['topic', 'topic_keywords', 'sentiment']]\n",
    "\n",
    "\n",
    "    def get_closest_words(self, reviews, centroid):\n",
    "        word_distances = {}\n",
    "        for r in reviews:\n",
    "            review_words = [w for w in word_tokenize(r) if(w not in self.STOPWORDS)]\n",
    "            for w in review_words:\n",
    "                word_embedding = embed([w]) # return 512 dimensional vector for the word 'w'\n",
    "                # how similar is the word embedding to the topic's centroid (avg of the cluster sample's embeddings)\n",
    "                word_distances[w] = self.cosine_similarity(word_embedding, centroid) # 1 it means match, closer to 0 means different\n",
    "        # done collecting the distances of the words to the topic's center\n",
    "        top_5_keywords = sorted([(word_distances[w], w) for w in word_distances])[-5:]\n",
    "        return \",\".join([x[1] for x in top_5_keywords])\n",
    "\n",
    "    def cosine_similarity(self, x, y):\n",
    "        # x,y are both the appropriate dimension\n",
    "        x = x.reshape(self.EMBEDDING_DIM,)\n",
    "        y = y.reshape(self.EMBEDDING_DIM,)\n",
    "        # calculate cosine similarity\n",
    "        dotproduct = x.dot(y)\n",
    "        x_mag = x.dot(x)**0.5\n",
    "        y_mag = y.dot(y)**0.5\n",
    "        # returns closer to 1 if x and y are similar, closer to 0 if they are different\n",
    "        return dotproduct/(x_mag * y_mag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ab4d91b9-9be0-4e1b-abca-d0702e124ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = ReviewsTopicModel(Air_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "86bc448e-13bc-4943-b03c-7cf52048d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.elbow_plot() # going to use 40 clusters i.e. 40 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "916445e5-ffd4-4fa0-9923-46140d05f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "topic_model.create_topics(num_topics=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "bdb80126-4a8f-4725-8664-2f96f34a7526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_keywords</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hannover - lhr. what a miserable experience this was. this return ticket was £950 for a total of about 140 mins flying time. i checked in online and there was considerable delays on this as there was following a phone call back to the uk an equipment change from an a319 to an a320. anyway i checked in online eventually and made my way through security. i asked an information post - as to where the club   business class lounge was and i was told it was land side and between this terminal and the next terminal. i could not believe it. surely a simple prompt online when checking in - could have told me this. flight left on time a reasonable light lunch and three gin and tonics later we got stacked over the east end for 25 minutes but landed ahead of schedule. a miserable experience from the so called worlds favorite airline.</th>\n",
       "      <td>1</td>\n",
       "      <td>passengers,airlines,inflight,ryanair,airline</td>\n",
       "      <td>-0.999208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncl-lhr-lax   las-lhr-ncl. ncl-lhr a320. comfortable enough for only a 1hr flight. crew did a great job serving a full flight in such a short space of time. overhead bins were full and was a bit tricky finding space. some passengers had put very small bags overhead and not under seats and refused to take them down it did seem people have more carry-on than allowed. took off on time and arrived early but this meant no stand available for 15mins. lhr-lax on a380. paid to get two economy seats on the upper deck together and was worth the money as no stranger next to us no moving for loo breaks etc. aircraft excellent ife great (games were good moving maps etc also great) crew superb food was nice (first meal very good!) and the ice lollies were a great touch but did think an extra drinks service would have been good. we were close to a galley so easy enough to go and ask for drinks which we did two three times. seat was good but equal space to the earlier a320. extra bin beside seat was useful. the arm rest doesnt go all the way up which was a bit of a pain. take off delayed by a fault on the airbridge but arrived on time - takes a while to get off due to number of people. las-lhr on a b747. older aircraft and compared to the brand new a380 it showed again paid to get two seats together which was worth it. seat ok but not as comfortable as previous flights food was ok ife was ok but my ptv was off centre so had to watch sideways. overall just an ok flight. crew were friendly and didnt hide away all night which normally happens on late flights with other carriers. my only problem was the arm rest didnt go up and when the seat in front of me reclined i couldnt get out. lhr-ncl on a a319. super quick flight not 100% full but crew again worked quickly to get everyone drinks and snacks. arrived 15min early but took a while for bags to come off at ncl.</th>\n",
       "      <td>2</td>\n",
       "      <td>qantas,legroom,airline,in-flight,inflight</td>\n",
       "      <td>-0.995106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flew from lgw to pfo and back recently. plane was old tatty 737 but at least we got the 34 of legroom which the refitted planes no longer have. flights were on time both ways food was reasonably good &amp; cabin staff were charming (specially on the outboard flight). i was surprised to find ba no longer has a club lounge at paphos and even more surprised to find that there was a comfortable lounge there that ba club europe passengers were unable to use. we were given vouchers as compensation and thought we would at least get a glass of wine and a sandwich - but no. the vouchers were of such low value they could only be redeemed for things like a local beer crisps and chewing gum. even though the flights were quite good i feel that ba are treating their club europe passengers with contempt by denying them any lounge access or reasonable compensation - also by refitting their aircraft to give passengers less seat width and the same legroom as economy. why pay a premium price for a non premium product?</th>\n",
       "      <td>2</td>\n",
       "      <td>qantas,legroom,airline,in-flight,inflight</td>\n",
       "      <td>0.962851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhr-jnb (south africa). booking done from site www.britishairways.com and the check-in too. the time boarding was done with great quality in terminal 5 in heathrow airport (pier c gate 65) and schedule. cabin crew was fantastic. the flight was very good the quality of the plane provides an excellent trip. takeoff and landing very smooth. the rest position of the seats makes in upper deck the legroom a little tight. do not choose the emergency exit seats because they do not have access to windows and are narrower because the table and the monitor are on the armrest. jnb-lhr. 747-400. it is a much older plane. however the trip was very good after crossing the storm just outside johannesburg.</th>\n",
       "      <td>5</td>\n",
       "      <td>recline,inflight,a380,cathay,legroom</td>\n",
       "      <td>0.996261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flew earlier this month lhr to ist in club europe. good smooth uneventful trip. good lounge at terminal 5. food and service onboard was very good. priority boarding and priority pass for immigration in turkey. however it is difficult to categorise the seating and space with business class. in fact the amount of room available seemed little different to economy.</th>\n",
       "      <td>4</td>\n",
       "      <td>ryanair,easyjet,in-flight,inflight,airline</td>\n",
       "      <td>-0.947689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flew lhr - vie return operated by bmi but ba aircraft. a319 aircraft was clearly new and very clean. the crew were smiling friendly and helpful. no in-flight entertainment but not a problem on this short-haul flight. delicious lunch was served - ham and mustard sub roll and unlimited drinks available. have flown british airways on this route many times now and they have never had a flaw in decent service and staff whether on the ground or in the skies.</th>\n",
       "      <td>4</td>\n",
       "      <td>ryanair,easyjet,in-flight,inflight,airline</td>\n",
       "      <td>0.998350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lhr to ham. purser addresses all club passengers by name boarding a little late but left on time. food good for short flight. overall excellent.</th>\n",
       "      <td>4</td>\n",
       "      <td>ryanair,easyjet,in-flight,inflight,airline</td>\n",
       "      <td>0.994867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my son who had worked for british airways urged me to fly british airways to kansas city. he recommended me to join the executive club. i went ahead and booked my flight back in may. very reasonable price. as they are in an alliance with american airlines my outward journey was with american airlines. they were helpful even booking my seats to chicago then onto kansas at no cost. problem was on my return. i duly waited to book my seat on the chicago flight 24 hours prior to check-in. as this was with ba i tried for an hour to choose a seat to no avail. my itinerary came up but told me i was being redirected to american. so i called ba they told me i was to check in at kansas city before i could have a seat assigned. so i called american a very unhelpful person told me that i had to go to back to ba. i called ba again after explaining i had seat booked with american from kansas but could not get one with ba she put me on hold for 15 minutes and told me i had a seat - trouble was it was the one from kansas to chicago. perhaps the powers that be can sort this out. it was most frustrating. the journey was fine staff polite in-flight entertainment excellent.</th>\n",
       "      <td>9</td>\n",
       "      <td>airways,stewardesses,lhr,heathrow,in-flight</td>\n",
       "      <td>-0.965341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>london city-new york jfk via shannon on a318 but had really nice seats and professional crew. meal served was very tasty and fresh. overall a very good flight would use this airline again.</th>\n",
       "      <td>3</td>\n",
       "      <td>a380,qantas,airline,in-flight,inflight</td>\n",
       "      <td>0.999676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sin-lhr ba12 b747-436 first class. old aircraft (1998) with seats that are not that private but there are only a few of us in the cabin so ok. a bit tatty but i think the planes are being replaced by a380s soon. seat itself is comfortable enough. inflight entertainment awful: fuzzy screen (low resolution lcd screen way passed its sell-by date) with limited options. inconveniently has to be pulled around to be seen and put away for t off and landing. seat comfortable enough for sleeping. food and service quintessentially english which is the only real reason to fly ba nowadays - the product just doesnt match other airlines. toilet cramped and awful but it has a window!</th>\n",
       "      <td>5</td>\n",
       "      <td>recline,inflight,a380,cathay,legroom</td>\n",
       "      <td>-0.963434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    topic  \\\n",
       "hannover - lhr. what a miserable experience thi...      1   \n",
       "ncl-lhr-lax   las-lhr-ncl. ncl-lhr a320. comfor...      2   \n",
       "flew from lgw to pfo and back recently. plane w...      2   \n",
       "lhr-jnb (south africa). booking done from site ...      5   \n",
       "flew earlier this month lhr to ist in club euro...      4   \n",
       "...                                                   ...   \n",
       "flew lhr - vie return operated by bmi but ba ai...      4   \n",
       "lhr to ham. purser addresses all club passenger...      4   \n",
       "my son who had worked for british airways urged...      9   \n",
       "london city-new york jfk via shannon on a318 bu...      3   \n",
       "sin-lhr ba12 b747-436 first class. old aircraft...      5   \n",
       "\n",
       "                                                                                  topic_keywords  \\\n",
       "hannover - lhr. what a miserable experience thi...  passengers,airlines,inflight,ryanair,airline   \n",
       "ncl-lhr-lax   las-lhr-ncl. ncl-lhr a320. comfor...     qantas,legroom,airline,in-flight,inflight   \n",
       "flew from lgw to pfo and back recently. plane w...     qantas,legroom,airline,in-flight,inflight   \n",
       "lhr-jnb (south africa). booking done from site ...          recline,inflight,a380,cathay,legroom   \n",
       "flew earlier this month lhr to ist in club euro...    ryanair,easyjet,in-flight,inflight,airline   \n",
       "...                                                                                          ...   \n",
       "flew lhr - vie return operated by bmi but ba ai...    ryanair,easyjet,in-flight,inflight,airline   \n",
       "lhr to ham. purser addresses all club passenger...    ryanair,easyjet,in-flight,inflight,airline   \n",
       "my son who had worked for british airways urged...   airways,stewardesses,lhr,heathrow,in-flight   \n",
       "london city-new york jfk via shannon on a318 bu...        a380,qantas,airline,in-flight,inflight   \n",
       "sin-lhr ba12 b747-436 first class. old aircraft...          recline,inflight,a380,cathay,legroom   \n",
       "\n",
       "                                                    sentiment  \n",
       "hannover - lhr. what a miserable experience thi...  -0.999208  \n",
       "ncl-lhr-lax   las-lhr-ncl. ncl-lhr a320. comfor...  -0.995106  \n",
       "flew from lgw to pfo and back recently. plane w...   0.962851  \n",
       "lhr-jnb (south africa). booking done from site ...   0.996261  \n",
       "flew earlier this month lhr to ist in club euro...  -0.947689  \n",
       "...                                                       ...  \n",
       "flew lhr - vie return operated by bmi but ba ai...   0.998350  \n",
       "lhr to ham. purser addresses all club passenger...   0.994867  \n",
       "my son who had worked for british airways urged...  -0.965341  \n",
       "london city-new york jfk via shannon on a318 bu...   0.999676  \n",
       "sin-lhr ba12 b747-436 first class. old aircraft...  -0.963434  \n",
       "\n",
       "[309 rows x 3 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "033fc3f7-c6b8-4658-bd2d-90a82244edce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flight,landing,boarding,iced,cabin'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.topics_keywords[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "515f3cf2-bbaa-4f97-b334-aabc89c2bd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_keywords</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>✅ trip verified  london heathrow to lisbon. mediocre. the flight was very smooth and arrived on time. cabin service left a great deal to be desired and staff seemed to be just going through the motions. no bread roll was offered during meal service and despite requesting a glass of wine to accompany the meal this was not forthcoming and staff required a ‘nudge’ before it was delivered. not a great club europe experience.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>-0.999257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified   flight from gatwick to barbados. check in and business lounge were good. it looks like they had added champagne to the self service drinks which is a positive. breakfast was good. flight left on time boarding well run. i have not flown in their economy cabin for a while and it seems ok. new configuration but that does come with panasonic ife system which is way better than the old rockwell collins systems. food was fine and service friendly.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>0.998769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified   san francisco to london. efficient check in by friendly agent who offered an upgrade to first at $760 per person which we declined. refurbished lounge was spacious and comfortable with nice selection of snacks. boarding on time but could have been better controlled. flight left and landed ahead of schedule. flight attendants were excellent and the food is vastly improved compared to our last trip. business class is not cheap but we had an excellent flight with no complaints.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>0.999258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified  mexico city to barcelona via london heathrow. the b787 is an incredible plane. the legroom is quite good, the seat is comfortable and the ife has a great number of movies, series and music. the food is average, the first meal was meat with mashed potatoes, salad and wine. not very tasty. the breakfast was scrambled eggs with mushrooms, fruit and a muffin, it was delicious! the cabin crew was ok. not bad, not excellent. we arrived on time and was a great flight. on the second flight the cabin crew appeared twice. no ife, no onboard service. it’s almost like a low cost. i recommend for long flights, but not for european flights.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>0.999423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified  glasgow to london. smooth flight, departure arrival on time. boarding was quick, the seat was ok. although i had pre-ordered a vegetarian option, the caterer hadnt provided any (so they said) - but the flight attendant quickly solved the issue. the food was good, and the wine (french, bourgogne) also surprisingly good. flight attendant was professional, polite and attentive to detail. all in all, a great flight.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>0.999720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified  mexico city to barcelona via london heathrow. the b787 is an incredible plane. the legroom is quite good, the seat is comfortable and the ife has a great number of movies, series and music. the food is average, the first meal was meat with mashed potatoes, salad and wine. not very tasty. the breakfast was scrambled eggs with mushrooms, fruit and a muffin, it was delicious! the cabin crew was ok. not bad, not excellent. we arrived on time and was a great flight. on the second flight the cabin crew appeared twice. no ife, no onboard service. it’s almost like a low cost. i recommend for long flights, but not for european flights.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>0.999423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified  glasgow to london. smooth flight, departure arrival on time. boarding was quick, the seat was ok. although i had pre-ordered a vegetarian option, the caterer hadnt provided any (so they said) - but the flight attendant quickly solved the issue. the food was good, and the wine (french, bourgogne) also surprisingly good. flight attendant was professional, polite and attentive to detail. all in all, a great flight.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>0.999720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified   belfast to san francisco via london. check-in at belfast city was fast and trouble free and security was completed with-in just a few minutes with no queues to mention. boarding was direct from the business lounge and on time as was departure. a full breakfast service was carried out including hot towels, hot breakfast, tea and coffee along with drinks from the bar on request. the galleries lounge in terminal 5 at heathrow was very busy with limited seats available. boarding for the second flight began on time and departure swift. the inflight service was top notch with a very capable crew looking after the customers on the upper deck in a professional and discrete manner. food was plentiful and tasty, entertainment perfectly adequate and seat comfort fine. no complaints at all about the flight and would recommend british airways.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>-0.995813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified   london to abu dhabi. this is the daytime flight from london. a very good flight. the food was excellent for economy (particularly in view of etihad‘s disastrous changes in food service). the children’s meals were excellent. the entertainment system was great with a good selection. it makes a big difference having the entertainment system on when you board and not turn it off until the plane has reached the gate, especially when flying with children (etihad, why don’t you do this?). the cabin crew were good. economy in the 787 is cramped but probably no worse than many. good value flight, especially as the only other carrier to abu dhabi is etihad.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>0.999532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>✅ trip verified   london to shanghai. the concorde room in heathrow terminal 5 was amazing, the dinner experience was great and the food was delicious. however, the first galleries was overcrowded and the buffet was bad. on the plane, the crew was very friendly and nice. dinner service was finished 1 hour after take off, the food was okay. bed was made after dinner and it was very comfortable, perhaps the best i have had. the entertainment system was not as good as other airlines like qatar airlines and emirates. overall, the journey was great.</th>\n",
       "      <td>0</td>\n",
       "      <td>legroom,airlines,emirates,flown,inflight</td>\n",
       "      <td>0.985600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    topic  \\\n",
       "✅ trip verified  london heathrow to lisbon. med...      0   \n",
       "✅ trip verified   flight from gatwick to barbad...      0   \n",
       "✅ trip verified   san francisco to london. effi...      0   \n",
       "✅ trip verified  mexico city to barcelona via l...      0   \n",
       "✅ trip verified  glasgow to london. smooth flig...      0   \n",
       "...                                                   ...   \n",
       "✅ trip verified  mexico city to barcelona via l...      0   \n",
       "✅ trip verified  glasgow to london. smooth flig...      0   \n",
       "✅ trip verified   belfast to san francisco via ...      0   \n",
       "✅ trip verified   london to abu dhabi. this is ...      0   \n",
       "✅ trip verified   london to shanghai. the conco...      0   \n",
       "\n",
       "                                                                              topic_keywords  \\\n",
       "✅ trip verified  london heathrow to lisbon. med...  legroom,airlines,emirates,flown,inflight   \n",
       "✅ trip verified   flight from gatwick to barbad...  legroom,airlines,emirates,flown,inflight   \n",
       "✅ trip verified   san francisco to london. effi...  legroom,airlines,emirates,flown,inflight   \n",
       "✅ trip verified  mexico city to barcelona via l...  legroom,airlines,emirates,flown,inflight   \n",
       "✅ trip verified  glasgow to london. smooth flig...  legroom,airlines,emirates,flown,inflight   \n",
       "...                                                                                      ...   \n",
       "✅ trip verified  mexico city to barcelona via l...  legroom,airlines,emirates,flown,inflight   \n",
       "✅ trip verified  glasgow to london. smooth flig...  legroom,airlines,emirates,flown,inflight   \n",
       "✅ trip verified   belfast to san francisco via ...  legroom,airlines,emirates,flown,inflight   \n",
       "✅ trip verified   london to abu dhabi. this is ...  legroom,airlines,emirates,flown,inflight   \n",
       "✅ trip verified   london to shanghai. the conco...  legroom,airlines,emirates,flown,inflight   \n",
       "\n",
       "                                                    sentiment  \n",
       "✅ trip verified  london heathrow to lisbon. med...  -0.999257  \n",
       "✅ trip verified   flight from gatwick to barbad...   0.998769  \n",
       "✅ trip verified   san francisco to london. effi...   0.999258  \n",
       "✅ trip verified  mexico city to barcelona via l...   0.999423  \n",
       "✅ trip verified  glasgow to london. smooth flig...   0.999720  \n",
       "...                                                       ...  \n",
       "✅ trip verified  mexico city to barcelona via l...   0.999423  \n",
       "✅ trip verified  glasgow to london. smooth flig...   0.999720  \n",
       "✅ trip verified   belfast to san francisco via ...  -0.995813  \n",
       "✅ trip verified   london to abu dhabi. this is ...   0.999532  \n",
       "✅ trip verified   london to shanghai. the conco...   0.985600  \n",
       "\n",
       "[240 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.topics_df.query(\"topic == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b474fee-9675-476f-8e61-5ffc15ff3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at average sentiment per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "af97e14b-0b60-4dd7-b4f0-05b39c54cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline_topic_model = topic_model.topics_df.groupby(['topic', 'topic_keywords']).agg({'sentiment': 'mean'}).reset_index()\\\n",
    "    .sort_values(by='sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "4cc700c5-dd0b-470c-8acb-77701961d638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_keywords</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i was on ba 835 from dublin to lhr on 25th july 2014 which left dublin at 13.05 and my travel plans were such that i had sufficient time to connect with my flight from lhr to hong kong. on leaving dublin the pilot opined that it was a good day to fly! on reaching lhr we were informed that due to thunderstorms we were to be diverted to gatwick and were running out of fuel. in summary we sat on the tarmac at gatwick for over two hours with only scant updates as to when we would be taking off for lhr and the temperature inside the cabin became oppressive which added to the misery. on reaching lhr ba staff were in my opinion ineffectual with a sorry and shrug of the shoulders and with no real assistance for those passengers on connecting flights. i was lucky as i managed to get on my flight to hong kong with cathay pacific but with only moments to spare after a dash to terminal 3. whilst i understand the volatility of the weather the real point of my review is that ba appears to have abandoned the basics of customer service and this is clearly reflected in bas absence in the top 10 airline ratings. could do a lot better!</th>\n",
       "      <td>0</td>\n",
       "      <td>hong,belfast,lhr,airline,cathay</td>\n",
       "      <td>-0.990500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flew from lhr to hong kong april 13th 2014 ba 25 and the flight took off 1 hour late. therefore as i had an onwards connection to jakarta with limited time to get my connection i asked on board about help with getting my onwards boarding card to jakarta as ba in belfast refused to issue me a boarding card. the csd was not seen nor did he even come to speak with me even though i am ggl member. the only help i got was from one of the hong kong based air stewardesses who went out of her to help me. without her help i would have missed my onwards to jakarta. certainly not impressed by the service. i made a follow up compliant however never received any response.</th>\n",
       "      <td>0</td>\n",
       "      <td>hong,belfast,lhr,airline,cathay</td>\n",
       "      <td>-0.998438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    topic  \\\n",
       "i was on ba 835 from dublin to lhr on 25th july...      0   \n",
       "flew from lhr to hong kong april 13th 2014 ba 2...      0   \n",
       "\n",
       "                                                                     topic_keywords  \\\n",
       "i was on ba 835 from dublin to lhr on 25th july...  hong,belfast,lhr,airline,cathay   \n",
       "flew from lhr to hong kong april 13th 2014 ba 2...  hong,belfast,lhr,airline,cathay   \n",
       "\n",
       "                                                    sentiment  \n",
       "i was on ba 835 from dublin to lhr on 25th july...  -0.990500  \n",
       "flew from lhr to hong kong april 13th 2014 ba 2...  -0.998438  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.topics_df.query(\"topic == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "9662f128-2942-44c3-a885-f937df75a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline_topic_model.to_excel(r\"C:\\Users\\user\\Desktop\\For Github\\Airline_TopicModelling.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0fbb9-247d-498f-8e1e-bdfdb6ddae84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
